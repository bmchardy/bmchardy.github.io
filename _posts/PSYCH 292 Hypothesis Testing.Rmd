---
title: 'PSYCH 292: Hypothesis Testing'
author: "Bobby McHardy, for the University of Waterloo's Psychology Society"
date: "December 5, 2020"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 3
    number_sections: true
---

```{r preppack, include=FALSE}
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc()
library("tibble")
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
```
```{r dataload, echo=FALSE}
# set the working directory for this project; this is where the data is located
setwd("C:/Users/26hmk/Documents/GitHub/PSYCH-292-Statistics-Tutorials")
tbl_z <- read.csv("ztable-05.csv")
tbl_t <- read.csv("ttable-05.csv")
```

In this PSYCH 292 tutorial, we are going to focus on t-tests. We'll introduce the essential concepts as we walk through a pratical example.

While most of the focus of this tutorial will be on statisics, we'll also look at how we can perform these calculations in a statistical programming language called "R". I'll put the "**Using R**" heading throughout the tutorial to denote optional information about the "R" programming language! Enjoy :)

# Our Data

We'll be conducting our t-tests on a dataset of N = 18 participants. These (example) data describe the experiences of our 18 participants in an experiment about Music Genres and Well-Being.

## Experimental Procedure

We randomly asked 18 students in our PSYCH 292 class to participate. Each participant in the *experiment* began by reporting their *baseline* (initial) Well-Being score. Well-Being was *operationalized* as a *self-report* measure of their perceived health and happiness. Participants rated their Well-Being on a score from 1 (A very low Well-Being) to 7 (A very high Well-Being). Participants were also asked to report the number of coffees that they drink on an average day because we think that Coffee Consumption might be a *predictor* variable of one's Well-Being. Knowing how much coffee each participant drinks per day allows us to *control for* Coffee Consumption.

After we measured our *baseline* Well-Being score and asked about Coffee Consumption, we began the *experimental manipulation*. The *indepenent (manipulated) variable* is Music Genre. We *randomly assigned* each participant to one of three Music Genre *conditions* (either Classical, Blues, or Control). In the Classical Music Genre condition, the participants were asked to listen to 15 minutes of Classical music when they first wake up for one week. Likewise, in the Blues Music Genre condition, the participants were asked to listen to 15 minutes of Blues music when they first wake up for one week. In the *control condition*, participants were not asked to listen to any music for the week.

At the end of the week, we measured (in a *post-test*) the Well-Being of each participant again using the same 1-7 *self-report* measure.

**Recall** that this is an *experiment* because we are *manipulating* our *independent variable* (Music Genre) and *randomly assigning* participants to *conditions* (*levels* of the independent variable). To make sure you are clear on all of these terms, review your PSYCH 291 notes.

## IV, DV, Conditions

In this dataset, the *independent variable (IV)* is Music Genre (either Classical, Blues, or Control *conditions*). The *dependent variable* is self-report Well-Being (from 1-7). We are also *controlling for* Coffee Consumption.

## Dataset

**Using R:** To load a datafile using R, we can use the following code.
```{r dataload2}
# In R, or other programming languages, we can assign values
# to variables just like you would in research.
#
# In this case, we are assigning the contents of the datafile
# on my computer to a variable called "wellbeing_intervention_data"
# using the "<-" (assignment) operator.
wellbeing_intervention_data <- read.csv("wellbeing_intervention_data.csv")
```

At the end of the week, these are the data we collected.

**Using R: ** To display a table of data, simply type the name of the variable like so!
```{r datatable}
wellbeing_intervention_data
```

The columns of this data table are *Participant*, *Coffess* (the number of cups that each participant reporting consuming daily), *Music* (the condition; one of *Classical*, *Blues*, or *Control*), *Baseline_WB* (the level of Well-Being each participant reported at the beginning of the experiment; between 1 and 7), and *Post_WB* (the level of Well-Being reported at the end of the week-long intervention).

# Questions

So what are some *research questions* that we might want to answer?

1. **"Does Blues music *cause* university students to experience different levels of well-being than Classical music?"**
2. **"Does one week of classical music *lead to* greater reported well-being?"**

**Note** that *lead to* is another way to make a causal claim.

**Recall** that we can make a *causal claim* because our data are *experimental* (and abides by the 3 rules for causal claims). If you're unsure why this means that we can make a causal claim, look back on your PSYCH 291 notes.

How do we answer these questions?

# Hypothesis Testing

Put simply, **hypothesis testing** is a way to test whether a *hypothesis* we make about a *population* is true or false.

The only way to prove *for certain* that different music genres lead to different levels of well-being in the population of university students would be to experiment with *every* university student in the world (the entire population). It's not exactly reasonable for us to do that, so we have to settle for a best guess about what the sample data are telling us.

Doing this requires a new type of statistic (and a very powerful one). Before, we had to settle for descriptions of our sample (What is the mean? The median? The standard deviation?) These were called **descriptive statistics** because they described the sample of data exactly. For example, in our dataset above, the average number of coffees that the participants reportedly drink per day is exactly (rounded) `M = 2.389` and the number of participants in the experiment are `N = 18`. These statistics exactly describe aspects of our sample.

**Using R:** We can use R, for example, to find the well-being mean (descriptive statistic) for participants before and after a treatment of classical music.
```{r datadescriptives}
# subset selects only the rows of our wellbeing_intervention_data table
# that meet the criteria (Music must equal "Classical"). We then make a
# new variable called "classical_participants" that contains only that data.
classical_participants <- subset(wellbeing_intervention_data, Music == "Classical")

# Next, we can calculate means of the Baseline_WB and Post_WB columns
# (and assign those means to numerical variables)!
classical_baseline_wellbeing_M <- mean(classical_participants$Baseline_WB)
classical_post_wellbeing_M <- mean(classical_participants$Post_WB)

# We can even "print" (display) the results for all to see like so:
print(paste0("Before the intervention, the classical condition reported an average well-being of ", classical_baseline_wellbeing_M, ". After the intervention, these same participants reported an average well-being of ", classical_post_wellbeing_M, "."))
```

This shows us that well-being is higher on average in our sample after the weeklong intervention for the Classical group. But does this mean we have enough information to confirm our second research question ("Does one week of classical music *lead to* greater reported well-being?") No.

In the case of *hypothesis testing*, we cannot look at our sample and say for certain that "yes, one week of listening to classical music leads to greater well-being in the *population*" because there is no way to know this about the population for certain just based on our sample; any sample has *sampling error*. We're also moving away from descriptive statistics with this research question because we are no longer looking to *describe* our sample, we are looking to *infer* conclusions from the sample about the population.

We need to test our hypotheses using **inferential statistics**: *inferences* we make about the *population* using our sample. These statistics are no longer 'facts'! These are guesses about what our sample is saying based on probability.

# The Hypothesis

When we are testing our hypothesis, we talk about the *null hypothesis* and the *alternative hypothesis*.

The **null hypothesis**, written $H_0$, is the hypothesis that this difference does not exist. We might say that one group is *equivalent* to the other group. In our example, the *null hypothesis* is that "there is no population difference in well-being between baseline and after the Classical music intervention."

The **alternative hypothesis**, written $H_1$, is the hypothesis that there is a difference. We might say that one group is *not equivalent* to the other group. In our example, the *alternative hypothesis* is that "there is a population difference in well-being between baseline and after the Classical music intervention."

# The *t* Statistic

**Question:** How do we know if there is a difference between two groups?

You might be wondering if we can just simply compare the sample means of both groups and see if they're the same or not. This doesn't really work.

For our example,
$H_0$ = "no population difference in well-being between baseline and post-classical music intervention."
$H_1$ = "there is a population difference in well-being between baseline and post-lassical music intervention."

We know that the average well-being of the sample before the Classical music intervention was `r classical_baseline_wellbeing_M` (the 'pre-test' group). We also know that after a week of classical music the mean was found to be `r classical_post_wellbeing_M` (the 'post-test' group) in the sample. We can see that the two are different by `r (classical_post_wellbeing_M - classical_baseline_wellbeing_M)`. So we *know for a fact* that the means in the *sample* are different.

But that's not what we're asking. We're asking if these means are different in the *population*. This is a trickier question because we did not survey the entire population of students (of course).

## Remember *z*-Score?

Remember the *z*-Score from earlier in the course?

$$z = \frac{x-\mu}{\sigma}$$

$z$ is a great way to figure out how 'far' from the population mean ($\mu$) a value is, in terms of standard deviations of the population ($\sigma$). For example, if we knew that the (all-time) average December morning in Waterloo is -3°C (population $\mu = -3$) with a standard deviation of 1°C ($\sigma = 1$) and we measured that the morning of December 4th was -8°C ($x = -8$) in Waterloo, we could calculate a *z*-Score as follows:

$$z = \frac{x-\mu}{\sigma} = \frac{(-8)-(-3)}{1} =-5$$

This *z*-Score tells us that the morning of December 4th is actually 5 standard deviations below the average population temperature! Remember that we could look at our *z* table and see that only less than 0.00004% of days are expected to be below this level, so this is significantly below average! Brrrr

We can also use *z*-Scores to compare different samples when we're given the population standard deviation. If a sample of 30 people before the classical music intervention had an average well-being score of 2 ($\mu_1 = 2$) and if the same people after the classical music intervention had an average well-being score of 4 ($\mu_1 = 4$), we could calculate the *z*-Score. Of course, we need to know the standard deviation. If we are given the population standard deviations, then we're good to go. In this case, let's say that $\sigma_1 = 1.5$ and $\sigma_2 = 1$.

We need the standard error ($SE$), as you've done before, as follows:

$$SE = \sqrt{\frac{\sigma_1^2}{n} + \frac{\sigma_2^2}{n}} = \sqrt{\frac{1.5^2}{30} + \frac{1^2}{30}} = 0.32914$$

$$z = \frac{\mu_2-\mu_1}{SE} = \frac{4-2}{0.32914} = 6.08$$

We end up with a *z*-Score = 6.08. Remember that we're testing our *null hypothesis* that the two groups are the same (no difference). If there were no difference between the groups, we would expect there to be pretty close to a zero standard deviation difference between them, but we found a difference of over 6 standard devations!

If we search up the *z*-value in a *z* table, we see that this *z*-value is above the 99.999% of all possible z-values..

```{r ztable_ex1}
tbl_z
```

It's a crazy outlier. Remember that we only need to be above the 97.5% mark ($p < .05$) to reject the null hypothesis. We're well past it, so we reject $H_0$; we say "there is a significant difference between the two groups - our classical music intervention worked!"

So *z*-Scores are great, but we've just found a limitation to *z*-Scores here..

## What's wrong with the *z*-Score?

Nothing's *wrong* with the *z*-Score, but it has its limits. **The *z*-Score can only be used if we know the *population* standard deviation ($\sigma$).**

In the example above, we had to be told that the first group had a population standard deviation of $\sigma_1 = 1.5$ and that the second group had a population standard deviation of $\sigma_2 = 1$.

In the context of our problem: If I were to ask you what the average number of coffees a PSYCH 292 student drinks per day, what would you say? How would you measure it?

Being the astute PSYCH student that you are, you would probably gather a sample of PSYCH 292 students, ask them about their coffee drinking habits, find the mean, standard deviation and be on your way!

This is the right way to calculate the... sample... standard deviation, but it's not the same as the population standard deviation.

In order to calculate the population standard deviation, we would need to find the average number of coffees that *all* PSYCH 292 students at UW - and in the world, for that matter - drink. This is not at all realistic.

## The importance of the *t*-Statistic

This is where the *t*-Statistic comes into play! The *z*-Score lets us decide how different two samples are when we know the standard deviations of the populations from which the samples are drawn. As discussed above with the coffees, this is not always very practical.

**Usually we don’t know anything about the population.** In these cases, instead of a *z*-Score we use a *t*-Statistic.

The major difference between the two statistics is that **$z$-Scores require us to know population $\sigma$**, whereas **$t$-Statistics only require us to know the sample $sd$)**. We use these sample statistics to *estimate* the population within a margin of error, our $p$-value.

There are a few different types of *t*-Statistics, but they all involve calculating the difference between two values over (divided by) some measure of spread, just like a *z*-Score does.

# The Two Cases

There are two main cases where a *t*-statistic can be used.

## Dependent

(1) Dependent *t*-Test (sometimes called a 'paired *t*-Test')

This is the one that is most similar to what we were just doing above with the pre- and post-test classical music groups, only now we do not need to be given population standard deviations, because *t*-Tests kindly let us use the sample sd's!

It's called dependent because we're looking at differences within the same group of people, just over time or over some intervention.

Just as a *z*-Test looks like

$$z = \frac{\mu_2-\mu_1}{\sqrt{\frac{\sigma_1^2}{n} + \frac{\sigma_2^2}{n}}}$$

a dependent *t*-Test looks like

$$t = \frac{M_2-M_1}{\sqrt{\frac{SD_1^2}{n} + \frac{SD_2^2}{n}}}$$

It's honestly the same thing, we just do something different in the table when we look up our value of significance. To repeat: a t-test is still calculating the number of standard deviations between scores.

Let's say we have the same sample as our last example. The 30 people before the classical music intervention had an average well-being score of 2 ($M_1 = 2$) and had an average well-being score of 4 ($M_2 = 4$) after the intervention, just like above. The only difference this time is that we were **not** given the the population standard deviations. But we'll assume that we had all the raw data, so we were able to find the standard deviations of each sample. Let's say that $SD_1 = 1.5$ and $SD_2 = 1$. These are the exact same numbers as above!

So, not surprisingly, our result is exactly the same - it's just called a *t*-value instead of a *z*-value because we used sample standard deviations (estimates).

$$t = \frac{M_2-M_1}{\sqrt{\frac{SD_1^2}{n} + \frac{SD_2^2}{n}}} = \frac{4-2}{0.32914} = 6.08$$

So what's this big difference? Well.. when we calculate sample standard deviations, we're taking a bit of a "guess" because a sample will obviously not give us the exact standard deviation of the distribution. So really, using a *t* statistic introduces a bit more error than the *z* does because we're estimating a bit more of the problem.

The benefit of the *t*-statistic is that it accounts for this extra risk with something called "degrees of freedom".

**degrees of freedom** is a simple way to account for the added error induced by using estimated values in place of a true value. In this case, we're using estimated (sample) standard deviations in place of true (population) standard deviations, so we need to take the problem's degrees of freedom into account.

The biggest issue with using an estimate is that we're only using a sample number of people, not every person in the entire universe (like the population does). By having a small $N$ like this, we take on a greater risk that the sample $SD$ is not 100% accurate. In fact, the smaller the $N$, the greater chance of error there is.

For example, it only makes sense that if I take the well-being scores of $N = 1000$ PSYCH 292 students, I'll have a better idea of what the mean and standard deviation of the population is than if I only look at the well-being of $N = 5$ PSYCH 292 students.

Degrees of freedom take this into account because degrees of freedom is actually defined as follows:

$$df = N - 1$$

When degrees of freedom is a direct function the number of people in the sample ($N$) like this, we are able to use degrees of freedom in our statistical decision making process.

Let's introduce the *t* table:

```{r ttable_ex1}
tbl_t
```

The *t* table functions a little bit differently than the *z* table. When we use the *z* table, we find the percentile of the standard normal (Z) distribution by using a specific number of standard deviations.

If, like above, we were trying to look up $z = 6.08$, we would find that it is above 99.999% of all values in the distribution - this shows that we indeed have a difference greater than the 97.5% needed to show that $p < .05$ so that we can reject our null hypothesis ($H_0$).

In the case of the *t* table, we don't use our *t* value to look up the percentage (percentile). We actually use our degrees of freedom ($df$) to look up a level of significance (a *z* value).

In this example, we have a sample of size $N = 30$ people. This means that our degrees of freedom is $df = N - 1 = 30 - 1 = 29$. Looking this value up in the table, we find a "significance threshold" of $t = 1.699$ish.

What this truly means is that, for a sample of size $N = 30$, a *t* value of $t = 1.699$ is at that 97.5% mark on the Z distribution (so that $p < .05$). So as long as our *t* is greater than $1.699$, we have found an effect that is significant at the $p < .05$ level; enough to comfortably reject the null hypothesis.

Since our $t = 6.08$, we reject the null hypothesis ($p < .05$).

### The OG Question

Going back up to almost the start of this tutorial, we had the following null and alternative hypotheses:

$H_0$ = "no population difference in well-being between baseline and post-classical music intervention."
$H_1$ = "there is a population difference in well-being between baseline and post-classical music intervention."

Well! We have enough stats knowledge to figure this out now. Better still, we can try to use the R programming language to solve this.

We need to calculate the mean and standard deviation of PSYCH 292 students' well-being scores before the classical music intervention.

**Using R:** We'll display our data once again. We'll also use it to calculate some statistics!
```{r datatable_classical_descriptives}
# let's display the participants in the "Classical" condition
wellbeing_intervention_data %>% filter(Music == "Classical")

# let's calculate some descriptive statistics that we'll need
N_classical <- nrow(wellbeing_intervention_data %>% filter(Music == "Classical"))
M_pretest <- mean((wellbeing_intervention_data %>% filter(Music == "Classical"))$Baseline_WB)
SD_pretest <- sd((wellbeing_intervention_data %>% filter(Music == "Classical"))$Baseline_WB)
M_posttest <- mean((wellbeing_intervention_data %>% filter(Music == "Classical"))$Post_WB)
SD_posttest <- sd((wellbeing_intervention_data %>% filter(Music == "Classical"))$Post_WB)
```

**Using R:** We can also print these values!
```{r datatable_classical_descriptives_display}
# let's 'display' these values
print(N_classical)
print(M_pretest)
print(SD_pretest)
print(M_posttest)
print(SD_posttest)
```

**Using R:** And calculate our degrees of freedom using another (already existing) variable!
```{r datatable_classical_descriptives_df}
# let's 'display' these values
df <- N_classical - 1

# and we'll print it
print(df)
```

Okay. We know that $N$ = `r N_classical`, $M_1$ = `r M_pretest`, $M_2$ = `r M_posttest`, $SD_1$ = `r SD_pretest`, $SD_2$ = `r SD_posttest`, and $df$ = `r df`, so we have all the information we need to do some arithmetic! So let's calculate our *t* statistic using these statistics.

$$t = \frac{M_2-M_1}{\sqrt{\frac{SD_1^2}{N} + \frac{SD_2^2}{N}}} = \frac{5.5-4.5}{\sqrt{\frac{0.5477^2}{6} + \frac{1.0488^2}{6}}} = \frac{1}{0.483} = 2.07$$

**Using R:** We can also use R to calculate this *t* statistic as follows.
```{r datatable_classical_t}
# calculate t (sqrt is for a square root)
t <- (M_posttest - M_pretest) / sqrt((SD_pretest^2 + SD_posttest^2) / N_classical)

# and we'll print the value
print(t)
```

We get the same thing a whole lot quicker! Therefore, we find a $t = 2.07$ with $df = 5$. Let's look this value up in the *t* table.

```{r ttable_ex2}
tbl_t
```

We notice that a significant *t* value using only 5 degrees of freedom is $t_{significant} = 2.01$. Since the *t* value we calculated meets (and surpasses) this level, we reject the null hypothesis - that is, there is a significant chance that there is a difference between the pretest and posttest well-being samples; the classical music intervention appears to have worked!

This being said, we're only using $N = 6$ participants. Notice that the more participants we use, the lower the calculated *t* value needs to be to be significant ($p < .05$). As we discussed above, this makes sense because the larger our sample, the more we can believe that those standard deviations approach the real deal (the population standard deviations).

In APA-7 format, we might report this finding as follows:

"A significant change in self-report well-being was measured within the $N = 6$ participants between pre-test ($M_1 = 5.5$, $SD_1 = 0.55$) and post-test ($M_2 = 4.5$, $SD_2 = 1.05$) 7 days later ($t(5) = 2.07$, $p < .05$)."

## Independent

We're going to end the tutorial with the second major type of *t*-test we can perform.

(1) Independent Samples *t*-Test

This *t*-test is only slightly different from the above because, instead of looking at within-participant change across time or across intervention, we look at whether two different (independent) groups of participants experience significantly different change.

This type of question is useful if we were to investigate whether the change that is experienced in the Classical-condition participants over time is greater than the change that is naturally experienced in the control condition over time (For example, there may be maturation or history effects left uncontrolled that cause a natural increase in well-being. This aspect of control is one of the beautiful features of an experiment.)

Really, there are only two differences between the dependent and independent samples *t*. First, by design, two independent samples have the chance to be of different sample sizes ($n$'s).

Therefore, instead of just referring to $n$ in our *t*-statistic formula, we must consider the possibility of an $n_1$ and $n_2$. Plain and simple.

$$t = \frac{M_2-M_1}{\sqrt{\frac{SD_1^2}{n_1} + \frac{SD_2^2}{n_2}}}$$

The second difference is that, since we are now considering $n_1 + n_2$ participants in total (instead of only $n$ participants), we must use a different value for our degrees of freedom.

Instead we use $df = (n_1 - 1) + (n_2 - 1)$. It's almost the same.

We can then go about calculating our *t* the same as before. Let's do just that.

Recall that we already have all the values for the classical music condition:

**Using R:** We'll print these descriptive statistics a second time!
```{r datatable_classical_descriptives_display_again}
# let's 'display' these values
print(N_classical)
print(M_pretest)
print(SD_pretest)
print(M_posttest)
print(SD_posttest)
```

**Using R:** We'll compute the control condition descriptives now.
```{r datatable_control_descriptives}
# let's display the participants in the "Classical" condition
wellbeing_intervention_data %>% filter(Music == "Control")

# let's calculate some descriptive statistics that we'll need
N_control <- nrow(wellbeing_intervention_data %>% filter(Music == "Control"))
M_control_t1 <- mean((wellbeing_intervention_data %>% filter(Music == "Control"))$Baseline_WB)
SD_control_t1 <- sd((wellbeing_intervention_data %>% filter(Music == "Control"))$Baseline_WB)
M_control_t2 <- mean((wellbeing_intervention_data %>% filter(Music == "Control"))$Post_WB)
SD_control_t2 <- sd((wellbeing_intervention_data %>% filter(Music == "Control"))$Post_WB)
```

**Using R:** We'll print the control descriptive statistics now too!
```{r datatable_control_descriptives_display}
# let's 'display' these values
print(N_control)
print(M_control_t1)
print(SD_control_t1)
print(M_control_t2)
print(SD_control_t2)
```

We need a couple intermediate values to make this work. We're looking at the *change* in means, so let's ensure we're using those values.

```{r datatable_intermediate_descriptives}
# let's 'display' these values
M_classical_change <- M_posttest - M_pretest
M_control_change <- M_control_t2 - M_control_t1
SD_classical_change <- sqrt((SD_pretest^2 + SD_posttest^2) / N_classical)
SD_control_change <- sqrt((SD_control_t1^2 + SD_control_t2^2) / N_control)
```

From this, we figure out that the mean change in scores for classical participants was `r M_classical_change`, while mean change in the control condition was  `r M_control_change`. We also found the standard deviation of these changes; `r SD_classical_change` and `r SD_control_change`, respectively.

**Using R:** Okay. We'll compute the independent *t*-value now. Only this time, we're going to rely completely on R; we won't be calculating it by hand.
```{r datatable_control_t}
# calculate t (sqrt is for a square root)
t <- (M_classical_change - M_control_change) /
  sqrt((SD_classical_change^2 / N_classical)
         + (SD_control_change^2 / N_control))

# and we'll print the value
print(t)
```

Therefore, we find a $t = 2.335$ with $df = (6 - 1) + (6 - 1) = 10$. Let's look this value up in the *t* table.

```{r ttable_ex3}
tbl_t
```

For $df = 10$, we only need $t_{significant} = 1.812$ for us to have a significant effect. Since $t = 2.335$, we find that $t > t_{significant}$ and therefore we reject the null hypothesis that the change in well-being among classical participants was due to maturation and/or history.

Therefore, we believe the classical music intervention leads to an improvement in the well-being of PSYCH 292 students.

# Conclusion

This was a fun tutorial, but we've only scratched the surface of *t*-tests, statistics, and the R language.

There's also many more analyses that could be run on these data.

I hope you got something out of this! Thanks for joining me :))



(I'm going to go to bed now because running stats makes me lose track of time; it's 3AM and is therefore past my bedtime.)